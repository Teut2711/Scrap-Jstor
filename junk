
class FREE:
    def download_pdf(self):
        for i in selected:
            if self.articles[i].get("download_link"):
                self.driver.get(
                    self.articles[i]["download_link"])
            else:
                self.driver.get(
                    self.articles[i]["site_link"])
                self.get_unpaid()

    def get_unpaid(self):
        try:
            ele = self.driver.find_element_by_xpath(
                """//ul[@class='action-buttons mln']/li/a[contains(text(),
                    'Read')][contains(text(), 'Online')]""")
        except NoSuchElementException:
            try:
                return self.scrap_pdf()

            print("See the site")
        else:
            ele.click()

    def scrap_pdf(self):
        try:
            images = []
            while True:
                images.append(self.driver.find_element_by_xpath(
                    """//img[@id='page-scan-container']
                    [contains(@src,'data:image')]""")
                ).get_attribute("src")
                self.driver.find_element_by_xpath(
                    "//span[@aria-label='Next Page']").click()
        except NoSuchElementException:
            pass
        else:
            self.toPDF(images)

    @staticmethod
    def toPDF(file_name, list_of_base64=[]):
        list_of_base64 = [parse_base64(i) for i in list_of_base64]
        with open(f"{file_name}.pdf", "wb") as f:
            f.write(img2pdf.convert(list_of_base64))
        return f"{file_name}.pdf"

        def parse_base64(string):
            if string.startswith("data:image"):
                return b64decode(string.split(",")[1], validate=True)


class PAID(searchJstor):

    def __init__(self):
        self.
